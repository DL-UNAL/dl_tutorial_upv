{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('notebook_repr_html',True)\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "              'theme': 'league',\n",
    "              'transition': 'fade',\n",
    "              'center': 'false',\n",
    "              'overview' : 'true',\n",
    "              'start_slideshow_at': 'selected'\n",
    "})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks in Keras\n",
    "\n",
    "[Fabio A. Gonz√°lez](http://dis.unal.edu.co/~fgonza/), Universidad Nacional de Colombia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CIFAR-10  Dataset\n",
    "\n",
    "* Collected by [Krizhevsky et al.](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "* Labeled subsets of the 80 million tiny images dataset (http://people.csail.mit.edu/torralba/tinyimages/)\n",
    "* 60000 32x32 colour images in 10 classes (6000 images per class). \n",
    "* 50000 training images and 10000 test images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CIFAR-10  Dataset\n",
    "\n",
    "<img  src=\"cifar.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4de63419ce63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m           'horse', 'ship', 'truck']\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9402aaeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
    "          'horse', 'ship', 'truck']\n",
    "plt.imshow(X_train[3])\n",
    "print(LABELS[y_train[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_1\", activity_regularizer=None, trainable=True, input_dtype=\"float32\", batch_input_shape=[None, 32,..., activation=\"linear\", kernel_size=(3, 3), filters=32, strides=[1, 1], padding=\"same\", data_format=\"channels_last\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_2\", activity_regularizer=None, trainable=True, activation=\"linear\", kernel_size=(3, 3), filters=32, strides=[1, 1], padding=\"valid\", data_format=\"channels_last\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(name=\"maxpooling2d_1\", trainable=True, pool_size=[2, 2], strides=[2, 2], padding=\"valid\", data_format=\"channels_last\")`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(trainable=True, name=\"dropout_1\", rate=0.25)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_3\", activity_regularizer=None, trainable=True, activation=\"linear\", kernel_size=(3, 3), filters=64, strides=[1, 1], padding=\"same\", data_format=\"channels_last\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_4\", activity_regularizer=None, trainable=True, activation=\"linear\", kernel_size=(3, 3), filters=64, strides=[1, 1], padding=\"valid\", data_format=\"channels_last\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(name=\"maxpooling2d_2\", trainable=True, pool_size=[2, 2], strides=[2, 2], padding=\"valid\", data_format=\"channels_last\")`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(trainable=True, name=\"dropout_2\", rate=0.25)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(name=\"dense_1\", activity_regularizer=None, trainable=True, input_dim=None, activation=\"linear\", units=512, kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(trainable=True, name=\"dropout_3\", rate=0.5)`\n",
      "  return cls(**config)\n",
      "/home/sebas/Programas/Anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(name=\"dense_2\", activity_regularizer=None, trainable=True, input_dim=None, activation=\"linear\", units=10, kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "convolution2d_1 (Conv2D)       (None, 32, 32, 32)          896        \n",
      "______________________________________________________________________\n",
      "activation_1 (Activation)      (None, 32, 32, 32)          0          \n",
      "______________________________________________________________________\n",
      "convolution2d_2 (Conv2D)       (None, 30, 30, 32)          9248       \n",
      "______________________________________________________________________\n",
      "activation_2 (Activation)      (None, 30, 30, 32)          0          \n",
      "______________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)  (None, 15, 15, 32)          0          \n",
      "______________________________________________________________________\n",
      "dropout_1 (Dropout)            (None, 15, 15, 32)          0          \n",
      "______________________________________________________________________\n",
      "convolution2d_3 (Conv2D)       (None, 15, 15, 64)          18496      \n",
      "______________________________________________________________________\n",
      "activation_3 (Activation)      (None, 15, 15, 64)          0          \n",
      "______________________________________________________________________\n",
      "convolution2d_4 (Conv2D)       (None, 13, 13, 64)          36928      \n",
      "______________________________________________________________________\n",
      "activation_4 (Activation)      (None, 13, 13, 64)          0          \n",
      "______________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)  (None, 6, 6, 64)            0          \n",
      "______________________________________________________________________\n",
      "dropout_2 (Dropout)            (None, 6, 6, 64)            0          \n",
      "______________________________________________________________________\n",
      "flatten_1 (Flatten)            (None, 2304)                0          \n",
      "______________________________________________________________________\n",
      "dense_1 (Dense)                (None, 512)                 1180160    \n",
      "______________________________________________________________________\n",
      "activation_5 (Activation)      (None, 512)                 0          \n",
      "______________________________________________________________________\n",
      "dropout_3 (Dropout)            (None, 512)                 0          \n",
      "______________________________________________________________________\n",
      "dense_2 (Dense)                (None, 10)                  5130       \n",
      "______________________________________________________________________\n",
      "activation_6 (Activation)      (None, 10)                  0          \n",
      "======================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('100ep_cifar100d.h5')\n",
    "model.summary(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "#SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification of new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "idx = 102\n",
    "plt.imshow(X_test[idx])\n",
    "model.predict_proba(X_test[idx:idx+1], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def get_layer_values(model, layer, in_val):\n",
    "    return K.function([model.layers[0].input, K.learning_phase()],\n",
    "                      [model.layers[layer].output])([[in_val], 0])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Most likely labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "idx = 133\n",
    "plt.imshow(X_test[idx])\n",
    "plt.show()\n",
    "activations = get_layer_values(model, 16, X_test[idx])\n",
    "vals = [(activations[i], LABELS[i]) for i in range(10)]\n",
    "sorted(vals, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How does the network see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualize_weights(model, layer, shape=(4, 8)):\n",
    "    values = model.layers[layer].get_weights()[0]\n",
    "    filters = values.shape[3]\n",
    "    plt.figure(figsize=(9, 9./shape[1]*shape[0]))\n",
    "    for i in range(filters):\n",
    "        plt.subplot(shape[0], shape[1], i + 1)\n",
    "        plt.imshow(values[:,:,0,i], cmap=plt.get_cmap('gray'))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_layer(model, layer, in_val, shape=(8,4)):\n",
    "    values = get_layer_values(model, layer, in_val)\n",
    "    filters = values.shape[2]\n",
    "    plt.figure(figsize=(9, 9./shape[1]*shape[0]))\n",
    "    for i in range(filters):\n",
    "        plt.subplot(shape[0], shape[1], i + 1)\n",
    "        plt.imshow(values[:,:,i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "visualize_weights(model, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Internal representation (layer 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "idx = 133\n",
    "plt.figure(figsize=(2,2)); plt.imshow(X_test[idx]); plt.show()\n",
    "visualize_layer(model, 1, X_test[idx],shape=(4,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Internal representation (layer 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "visualize_layer(model, 3, X_test[idx],shape=(4, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Internal representation (layer 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "visualize_layer(model, 7, X_test[idx],shape=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Internal representation (layer 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "visualize_layer(model, 9, X_test[idx],shape=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
